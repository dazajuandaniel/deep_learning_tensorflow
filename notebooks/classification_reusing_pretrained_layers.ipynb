{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensorflow Play**\n",
    "\n",
    "Getting familiar with Tensorflow by developing a simple classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import utils as u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data from Keras\n",
    "X_train, X_test, X_valid, y_train, y_test, y_valid = u.get_fashion_mnist_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "booleans_train = [True if x in [0,1,2,3,4,5,6,7] else False for x in y_train]\n",
    "booleans_test = [True if x in [0,1,2,3,4,5,6,7] else False for x in y_test]\n",
    "booleans_valid = [True if x in [0,1,2,3,4,5,6,7] else False for x in y_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_a = X_train[booleans_train]\n",
    "xtest_a = X_test[booleans_test]\n",
    "xvalid_a = X_valid[booleans_valid]\n",
    "\n",
    "ytrain_a = y_train[booleans_train]\n",
    "ytest_a = y_test[booleans_test]\n",
    "yvalid_a = y_valid[booleans_valid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Showcase Pretrained Models**\n",
    "\n",
    "We have to train a model for labels `8` & `9`, but we only have a limited number of labels (200). We know that someone else, has already trained a similar task namely, classifies labels `0-7`. Given that some components could be reused, we are going to use that model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model A**\n",
    "\n",
    "First, we create an initial model that only classifies labels `0-7`. The idea is to then reuse this model to train labels `8` & `9`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a simple sequential model\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Flatten the input\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "\n",
    "# Add dense layers\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "\n",
    "# Add Final Layer\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "# Add Optimizer & Compile model\n",
    "optimizer = keras.optimizers.SGD(lr=0.3)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"../models/classification_reusing_pretrained_layers_a.h5\",\n",
    "                                                save_best_only=True)\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True,\n",
    "                                                  monitor='accuracy')\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(u.get_run_logdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.7900 - accuracy: 0.7039 - val_loss: 0.4356 - val_accuracy: 0.8304\n",
      "Epoch 2/30\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.4554 - accuracy: 0.8242 - val_loss: 0.4154 - val_accuracy: 0.8444\n",
      "Epoch 3/30\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.4063 - accuracy: 0.8454 - val_loss: 0.3898 - val_accuracy: 0.8511\n",
      "Epoch 4/30\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.3829 - accuracy: 0.8563 - val_loss: 0.3534 - val_accuracy: 0.8661\n",
      "Epoch 5/30\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.3588 - accuracy: 0.8651 - val_loss: 0.3830 - val_accuracy: 0.8536\n",
      "Epoch 6/30\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.3449 - accuracy: 0.8682 - val_loss: 0.3716 - val_accuracy: 0.8641\n",
      "Epoch 7/30\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.3311 - accuracy: 0.8762 - val_loss: 0.3809 - val_accuracy: 0.8651\n",
      "Epoch 8/30\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.3207 - accuracy: 0.8791 - val_loss: 0.3631 - val_accuracy: 0.8651\n",
      "Epoch 9/30\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.3112 - accuracy: 0.8810 - val_loss: 0.3922 - val_accuracy: 0.8521\n",
      "Epoch 10/30\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.3016 - accuracy: 0.8840 - val_loss: 0.3420 - val_accuracy: 0.8704\n",
      "Epoch 11/30\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2928 - accuracy: 0.8901 - val_loss: 0.3491 - val_accuracy: 0.8691\n",
      "Epoch 12/30\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2832 - accuracy: 0.8920 - val_loss: 0.3713 - val_accuracy: 0.8676\n",
      "Epoch 13/30\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2798 - accuracy: 0.8926 - val_loss: 0.3633 - val_accuracy: 0.8651\n",
      "Epoch 14/30\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2706 - accuracy: 0.8978 - val_loss: 0.3632 - val_accuracy: 0.8736\n",
      "Epoch 15/30\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2676 - accuracy: 0.8981 - val_loss: 0.3715 - val_accuracy: 0.8719\n",
      "Epoch 16/30\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2580 - accuracy: 0.9004 - val_loss: 0.3674 - val_accuracy: 0.8776\n",
      "Epoch 17/30\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2521 - accuracy: 0.9060 - val_loss: 0.3495 - val_accuracy: 0.8756\n",
      "Epoch 18/30\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2498 - accuracy: 0.9052 - val_loss: 0.3632 - val_accuracy: 0.8771\n",
      "Epoch 19/30\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2350 - accuracy: 0.9097 - val_loss: 0.3717 - val_accuracy: 0.8754\n",
      "Epoch 20/30\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2413 - accuracy: 0.9079 - val_loss: 0.3884 - val_accuracy: 0.8694\n",
      "Epoch 21/30\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2292 - accuracy: 0.9125 - val_loss: 0.3605 - val_accuracy: 0.8831\n",
      "Epoch 22/30\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2270 - accuracy: 0.9139 - val_loss: 0.4108 - val_accuracy: 0.8726\n",
      "Epoch 23/30\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2182 - accuracy: 0.9171 - val_loss: 0.3959 - val_accuracy: 0.8691\n",
      "Epoch 24/30\n",
      "1375/1375 [==============================] - 2s 1ms/step - loss: 0.2117 - accuracy: 0.9212 - val_loss: 0.3863 - val_accuracy: 0.8739\n",
      "Epoch 25/30\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2114 - accuracy: 0.9193 - val_loss: 0.3811 - val_accuracy: 0.8819\n",
      "Epoch 26/30\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2158 - accuracy: 0.9192 - val_loss: 0.3914 - val_accuracy: 0.8741\n",
      "Epoch 27/30\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.2068 - accuracy: 0.9211 - val_loss: 0.4126 - val_accuracy: 0.8716\n",
      "Epoch 28/30\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.1971 - accuracy: 0.9268 - val_loss: 0.4406 - val_accuracy: 0.8699\n",
      "Epoch 29/30\n",
      "1375/1375 [==============================] - 3s 2ms/step - loss: 0.2001 - accuracy: 0.9241 - val_loss: 0.3791 - val_accuracy: 0.8756\n",
      "Epoch 30/30\n",
      "1375/1375 [==============================] - 2s 2ms/step - loss: 0.1925 - accuracy: 0.9273 - val_loss: 0.3853 - val_accuracy: 0.8821\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_train = model.fit(xtrain_a, ytrain_a, epochs=30, validation_data=(xvalid_a, yvalid_a),\n",
    "                        callbacks=[checkpoint_cb,early_stopping_cb,tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model B - Try 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "booleans_train_b_8 = [True if x == 8 else False for x in y_train]\n",
    "booleans_test_b_8 = [True if x == 8 else False for x in y_test]\n",
    "booleans_valid_b_8 = [True if x == 8 else False for x in y_valid]\n",
    "\n",
    "booleans_train_b_9 = [True if x == 9 else False for x in y_train]\n",
    "booleans_test_b_9 = [True if x == 9 else False for x in y_test]\n",
    "booleans_valid_b_9 = [True if x == 9 else False for x in y_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_b_8 = X_train[booleans_train_b_8]\n",
    "xtest_b_8 = X_test[booleans_test_b_8]\n",
    "xvalid_b_8 = X_valid[booleans_valid_b_8]\n",
    "\n",
    "ytrain_b_8 = y_train[booleans_train_b_8]\n",
    "ytest_b_8 = y_test[booleans_test_b_8]\n",
    "yvalid_b_8 = y_valid[booleans_valid_b_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_b_9 = X_train[booleans_train_b_9]\n",
    "xtest_b_9 = X_test[booleans_test_b_9]\n",
    "xvalid_b_9 = X_valid[booleans_valid_b_9]\n",
    "\n",
    "ytrain_b_9 = y_train[booleans_train_b_9]\n",
    "ytest_b_9 = y_test[booleans_test_b_9]\n",
    "yvalid_b_9 = y_valid[booleans_valid_b_9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_b = np.concatenate([xtrain_b_8[0:100],xtrain_b_9[0:100]])\n",
    "xtest_b = np.concatenate([xtest_b_8,xtest_b_9])\n",
    "xvalid_b = np.concatenate([xvalid_b_8[0:100],xvalid_b_9[0:100]])\n",
    "\n",
    "ytrain_b = np.concatenate([ytrain_b_8[0:100],ytrain_b_9[0:100]])\n",
    "ytest_b = np.concatenate([ytest_b_8,ytest_b_9])\n",
    "yvalid_b = np.concatenate([yvalid_b_8[0:100],yvalid_b_9[0:100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain_b = np.array([1 if x == 8 else 0 for x in ytrain_b])\n",
    "ytest_b = np.array([1 if x == 8 else 0 for x in ytest_b])\n",
    "yvalid_b = np.array([1 if x == 8 else 0 for x in yvalid_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a simple sequential model\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# Flatten the input\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "\n",
    "# Add dense layers\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "\n",
    "# Add Final Layer\n",
    "model.add(keras.layers.Dense(2, activation=\"softmax\"))\n",
    "\n",
    "# Add Optimizer & Compile model\n",
    "optimizer = keras.optimizers.SGD(lr=0.3)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"../models/classification_reusing_pretrained_layers_b_a.h5\",\n",
    "                                                save_best_only=True)\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,\n",
    "                                                  restore_best_weights=True,\n",
    "                                                  monitor='accuracy')\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(u.get_run_logdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "7/7 [==============================] - 2s 237ms/step - loss: 2.6424 - accuracy: 0.5540 - val_loss: 0.5435 - val_accuracy: 0.6700\n",
      "Epoch 2/30\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.3085 - accuracy: 0.8666 - val_loss: 3.5729 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.6036 - accuracy: 0.5994 - val_loss: 0.3575 - val_accuracy: 0.9850\n",
      "Epoch 4/30\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 1.0325 - accuracy: 0.7996 - val_loss: 0.5093 - val_accuracy: 0.9700\n",
      "Epoch 5/30\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.8035 - accuracy: 0.9205 - val_loss: 0.6678 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6035 - accuracy: 0.6855 - val_loss: 0.5785 - val_accuracy: 0.8250\n",
      "Epoch 7/30\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.5221 - accuracy: 0.8975 - val_loss: 0.2556 - val_accuracy: 0.9900\n",
      "Epoch 8/30\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.5425 - accuracy: 0.8628 - val_loss: 0.5750 - val_accuracy: 0.7350\n",
      "Epoch 9/30\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.4595 - accuracy: 0.8395 - val_loss: 0.1727 - val_accuracy: 0.9950\n",
      "Epoch 10/30\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.4582 - accuracy: 0.8299 - val_loss: 1.1738 - val_accuracy: 0.5050\n",
      "Epoch 11/30\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.5401 - accuracy: 0.6538 - val_loss: 0.1237 - val_accuracy: 0.9900\n",
      "Epoch 12/30\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.4575 - accuracy: 0.9030 - val_loss: 0.9217 - val_accuracy: 0.5200\n",
      "Wall time: 2.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_train = model.fit(xtrain_b, ytrain_b, epochs=30, validation_data=(xvalid_b, yvalid_b),\n",
    "                        callbacks=[checkpoint_cb,early_stopping_cb,tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 3.5936 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.5936391353607178, 0.5]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train.model.evaluate(xtest_b, ytest_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applying Transfer Learning**\n",
    "\n",
    "When you train `model_B_on_A`, it will also affect `model_A`. If you want to avoid that, you need to clone `model_A` before you reuse its layers. To do this, you clone `model A`’s architecture with `clone_model()`, then copy its weights (since `clone_model()` does not clone the weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model(\"../models/classification_reusing_pretrained_layers_a.h5\")\n",
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you could train model_B_on_A for task B, but since the new output layer was initialized randomly it will make large errors (at least during the first few epochs), so there will be large error gradients that may wreck the reused weights. To avoid this, one approach is to freeze the reused layers during the first few epochs, giving the new layer some time to learn reasonable weights. To do this, set every layer’s trainable attribute to False and compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A = keras.models.Sequential(model_A_clone.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must always compile your model after you freeze or unfreeze layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_on_A.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer,\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can train the model for a few epochs, then unfreeze the reused layers (which requires compiling the model again) and continue training to fine-tune the reused layers for task B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "7/7 [==============================] - 1s 46ms/step - loss: 0.3618 - accuracy: 0.7703 - val_loss: 0.0629 - val_accuracy: 0.9900\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0773 - accuracy: 0.9912 - val_loss: 0.0455 - val_accuracy: 0.9950\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0489 - accuracy: 0.9924 - val_loss: 0.0411 - val_accuracy: 0.9950\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0741 - accuracy: 0.9892 - val_loss: 0.0302 - val_accuracy: 0.9950\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(xtrain_b, ytrain_b, epochs=4,\n",
    "                           validation_data=(xvalid_b, yvalid_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "7/7 [==============================] - 2s 315ms/step - loss: 0.0736 - accuracy: 0.9892 - val_loss: 0.0177 - val_accuracy: 0.9950\n",
      "Epoch 2/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0438 - accuracy: 0.9914 - val_loss: 0.0173 - val_accuracy: 0.9950\n",
      "Epoch 3/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0320 - accuracy: 0.9950 - val_loss: 0.0120 - val_accuracy: 0.9950\n",
      "Epoch 4/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0340 - accuracy: 0.9881 - val_loss: 0.0139 - val_accuracy: 0.9950\n",
      "Epoch 5/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0116 - accuracy: 0.9981 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
      "Epoch 6/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 7/16\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 8/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 9/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 10/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 11/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 12/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 13/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 14/16\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 15/16\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 16/16\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model_B_on_A.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "                     metrics=[\"accuracy\"])\n",
    "\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"../models/classification_reusing_pretrained_layers_b_b.h5\",\n",
    "                                                save_best_only=True)\n",
    "\n",
    "history = model_B_on_A.fit(xtrain_b, ytrain_b, epochs=16,\n",
    "                           validation_data=(xvalid_b, yvalid_b),\n",
    "                           callbacks=[checkpoint_cb,early_stopping_cb,tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step - loss: 0.0201 - accuracy: 0.9965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.020140551030635834, 0.9965000152587891]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.model.evaluate(xtest_b, ytest_b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
